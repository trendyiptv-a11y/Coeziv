// trigger redeploy 12nov25
// Redeploy fix analyze API (comentat ca sÄƒ nu mai dea SyntaxError)

export default async function handler(req, res) {
  // AcceptÄƒ doar POST È™i rÄƒspunde JSON mereu
  if (req.method !== "POST") {
    return res
      .status(405)
      .json({ error: "Method not allowed. Use POST /api/analyze" });
  }

  // Body safe (Vercel poate trimite string; Next API Ã®l parseazÄƒ deja)
  let body = {};
  try {
    body =
      typeof req.body === "string" ? JSON.parse(req.body || "{}") : (req.body || {});
  } catch {
    return res.status(400).json({ error: "Invalid JSON body." });
  }

  const { text, humanMode } = body;
  if (!text || typeof text !== "string") {
    return res.status(400).json({ error: "Missing text for analysis." });
  }

  if (!process.env.OPENAI_API_KEY) {
    return res.status(500).json({
      error: "Server misconfigured: OPENAI_API_KEY is missing.",
    });
  }

  try {
    const gptPrompt = `
EÈ™ti Motorul Coeziv 3.14Î” â€” un sistem de analizÄƒ factualÄƒ, logicÄƒ È™i semanticÄƒ bazat pe Formula Coeziunii 3.14Î”.

AnalizeazÄƒ afirmaÈ›ia urmÄƒtoare conform celor 3 axe fundamentale:
1. Factual (F) â€“ adevÄƒrul obiectiv verificabil.
2. Logic (L) â€“ coerenÈ›a cauzÄƒ-efect È™i raÈ›ionamentul intern.
3. Semantic (C) â€“ armonia È™i sensul exprimÄƒrii Ã®n context uman.

AcordÄƒ pentru fiecare o valoare Ã®ntre 0 È™i 3.14, apoi calculeazÄƒ V=(F+L+C)/3.
DeterminÄƒ verdictul: 0â€“1.04 âŒ, 1.05â€“2.09 âš ï¸, 2.10â€“3.14 âœ….

ReturneazÄƒ DOAR JSON VALID:
{
  "factual_score": number,
  "logic_score": number,
  "semantic_score": number,
  "V": number,
  "verdict": "scurt",
  "summary": "scurt"
}

AfirmaÈ›ia:
"${text}"
`.trim();

    // Cerere cÄƒtre OpenAI (fetch global Ã®n Node 18/20 pe Vercel)
    const gptResp = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: "gpt-4o-mini",
        temperature: 0.4,
        messages: [
          {
            role: "system",
            content:
              "EÈ™ti un evaluator de adevÄƒr conform Formulei Coeziunii 3.14Î”. RÄƒspunde strict cu JSON valid.",
          },
          { role: "user", content: gptPrompt },
        ],
      }),
    });

    if (!gptResp.ok) {
      const errText = await gptResp.text();
      return res.status(502).json({
        error: "OpenAI request failed",
        status: gptResp.status,
        detail: errText?.slice(0, 500),
      });
    }

    const gptData = await gptResp.json();
    const content = gptData?.choices?.[0]?.message?.content || "";

    // Parse robust al JSON-ului (acceptÄƒ È™i varianta cu ```json)
    function extractJson(str) {
      const fenced =
        str.match(/```json\s*([\s\S]*?)\s*```/) ||
        str.match(/```\s*([\s\S]*?)\s*```/);
      if (fenced) return fenced[1].trim();
      const start = str.indexOf("{");
      const end = str.lastIndexOf("}");
      if (start !== -1 && end !== -1 && end > start) return str.slice(start, end + 1);
      return str.trim();
    }

    let gptJson;
    try {
      gptJson = JSON.parse(extractJson(content));
    } catch {
      gptJson = {
        factual_score: 1.57,
        logic_score: 1.57,
        semantic_score: 1.57,
        V: 1.57,
        verdict: "Ambiguu (parsare eÈ™uatÄƒ)",
        summary: "Modelul nu a Ã®ntors JSON pur; s-a folosit fallback.",
      };
    }

    const safe = (v) => (typeof v === "number" && isFinite(v) ? v : 1.57);
    const F = safe(gptJson.factual_score);
    const L = safe(gptJson.logic_score);
    const C = safe(gptJson.semantic_score);

    function calcHumanResonance(txt) {
      const kws = ["suflet","iubire","armonie","adevÄƒr","luminÄƒ","viaÈ›Äƒ","coeziune","energie"];
      let r = 0;
      const low = txt.toLowerCase();
      for (const k of kws) if (low.includes(k)) r += 0.5;
      if (!/(?:\bnu\b|rÄƒu|fals|urÄƒ|greÈ™it)/i.test(low)) r += 0.5;
      return Math.min(r, 3.14);
    }
    const H = humanMode ? calcHumanResonance(text) : 0;
    const Vnum = humanMode ? (F + L + C + H) / 4 : (F + L + C) / 3;
    const V = Number(Vnum.toFixed(2));

    // CÄƒutare opÈ›ionalÄƒ (nu bloca dacÄƒ lipseÈ™te cheia)
    let sources = [];
    if (process.env.SERPER_API_KEY) {
      try {
        const serp = await fetch("https://google.serper.dev/search", {
          method: "POST",
          headers: {
            "Content-Type": "application/json",
            "X-API-KEY": process.env.SERPER_API_KEY,
          },
          body: JSON.stringify({ q: text, gl: "ro", hl: "ro" }),
        });
        if (serp.ok) {
          const serpData = await serp.json();
          sources = (serpData?.organic || []).slice(0, 5).map(r => ({
            title: r.title,
            link: r.link
          }));
        }
      } catch { /* ignore */ }
    }

    return res.status(200).json({
      mode: humanMode ? "Î”H" : "Î”",
      factual_score: F,
      logic_score: L,
      semantic_score: C,
      human_score: humanMode ? H : undefined,
      V,
      verdict: humanMode
        ? H > 2.5 ? "ğŸŒ¿ AdevÄƒr coeziv uman" : "âš–ï¸ Echilibru parÈ›ial uman"
        : gptJson.verdict || "â€”",
      summary: humanMode ? `${gptJson.summary || ""} (AnalizÄƒ Î”H)` : gptJson.summary || "â€”",
      sources,
    });
  } catch (err) {
    return res.status(500).json({
      error: "Eroare internÄƒ Ã®n analiza CoezivÄƒ 3.14Î”/Î”H.",
      detail: String(err?.message || err).slice(0, 500),
    });
  }
}
